import os
from langchain.schema.document import Document
from e5_embeddings import E5Embeddings
from langchain_community.vectorstores import FAISS

from document_processor_image import load_documents, split_documents  # ë°˜ë“œì‹œ ì´ í•¨ìˆ˜ê°€ í•„ìš”

# ê²½ë¡œ ì„¤ì •
NEW_FOLDER = "25.05.28 RAGìš© 2ì°¨ ì—…ë¬´í¸ëŒ ì·¨í•©ë³¸"
#NEW_FOLDER = "ì„ì‹œ"
VECTOR_STORE_PATH = "faiss_index_800image"

# 1. ì„ë² ë”© ëª¨ë¸ ë¡œë”©
def get_embeddings(model_name="intfloat/multilingual-e5-large-instruct", device="cuda"):
    return E5Embeddings(
        model_name=model_name,
        model_kwargs={'device': device},
        encode_kwargs={'normalize_embeddings': True}
    )

# 2. ê¸°ì¡´ ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ
def load_vector_store(embeddings, load_path="faiss_index_800image"):
    if not os.path.exists(load_path):
        raise FileNotFoundError(f"ë²¡í„° ìŠ¤í† ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {load_path}")
    return FAISS.load_local(load_path, embeddings, allow_dangerous_deserialization=True)

# 3. ë¬¸ì„œ ì„ë² ë”© ë° ì¶”ê°€
def add_new_documents_to_vector_store(new_folder, vectorstore, embeddings):
    print(f"ğŸ“‚ ìƒˆë¡œìš´ ë¬¸ì„œ ë¡œë“œ ì¤‘: {new_folder}")
    new_docs = load_documents(new_folder)
    new_chunks = split_documents(new_docs, chunk_size=800, chunk_overlap=100)

    print(f"ğŸ“„ ìƒˆë¡œìš´ ì²­í¬ ìˆ˜: {len(new_chunks)}")
    print(f"ì¶”ê°€ ì „ ë²¡í„° ìˆ˜: {vectorstore.index.ntotal}")
    vectorstore.add_documents(new_chunks)
    print(f"ì¶”ê°€ í›„ ë²¡í„° ìˆ˜: {vectorstore.index.ntotal}")

    print("âœ… ìƒˆë¡œìš´ ë¬¸ì„œê°€ ë²¡í„° ìŠ¤í† ì–´ì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")

# 4. ì „ì²´ ì‹¤í–‰
if __name__ == "__main__":
    embeddings = get_embeddings()
    vectorstore = load_vector_store(embeddings, VECTOR_STORE_PATH)
    add_new_documents_to_vector_store(NEW_FOLDER, vectorstore, embeddings)
    vectorstore.save_local(VECTOR_STORE_PATH)
    print(f"ğŸ’¾ ë²¡í„° ìŠ¤í† ì–´ ì €ì¥ ì™„ë£Œ: {VECTOR_STORE_PATH}")
