#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
ë²¡í„° ìŠ¤í† ì–´ ëª¨ë“ˆ: ë¬¸ì„œ ì„ë² ë”© ìƒì„± ë° ë²¡í„° ìŠ¤í† ì–´ êµ¬ì¶•
ë°°ì¹˜ ì²˜ë¦¬ ì ìš© + ì²­í¬ ê¸¸ì´ í™•ì¸ ì¶”ê°€
"""

import os
import argparse
import logging
from tqdm import tqdm
from langchain_community.vectorstores import FAISS
from langchain.schema.document import Document
from langchain_huggingface import HuggingFaceEmbeddings
from e5_embeddings import E5Embeddings

# ë¡œê¹… ì„¤ì •
logging.getLogger().setLevel(logging.ERROR)

def get_embeddings(model_name="intfloat/multilingual-e5-large-instruct", device="cuda"):
    print(f"[INFO] ì„ë² ë”© ëª¨ë¸ ë””ë°”ì´ìŠ¤: {device}")
    return E5Embeddings(
        model_name=model_name,
        model_kwargs={'device': device},
        encode_kwargs={'normalize_embeddings': True}
    )

def build_vector_store_batch(documents, embeddings, save_path="faiss_index_pymupdf_81", batch_size=4):
    if not documents:
        raise ValueError("ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. ë¬¸ì„œê°€ ì˜¬ë°”ë¥´ê²Œ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")

    texts = [doc.page_content for doc in documents]
    metadatas = [doc.metadata for doc in documents]

    # ì²­í¬ ê¸¸ì´ ì¶œë ¥
    lengths = [len(t) for t in texts]
    print(f"ğŸ’¡ ì²­í¬ ìˆ˜: {len(texts)}")
    print(f"ğŸ’¡ ê°€ì¥ ê¸´ ì²­í¬ ê¸¸ì´: {max(lengths)} chars")
    print(f"ğŸ’¡ í‰ê·  ì²­í¬ ê¸¸ì´: {sum(lengths) // len(lengths)} chars")

    # ë°°ì¹˜ë¡œ ë‚˜ëˆ„ê¸°
    batches = [texts[i:i + batch_size] for i in range(0, len(texts), batch_size)]
    metadata_batches = [metadatas[i:i + batch_size] for i in range(0, len(metadatas), batch_size)]

    print(f"Processing {len(batches)} batches with size {batch_size}")
    print(f"Initializing vector store with batch 1/{len(batches)}")

    # âœ… from_documents ì‚¬ìš©
    first_docs = [
        Document(page_content=text, metadata=meta)
        for text, meta in zip(batches[0], metadata_batches[0])
    ]
    vectorstore = FAISS.from_documents(first_docs, embeddings)

    for i in tqdm(range(1, len(batches)), desc="Processing batches"):
        try:
            docs_batch = [
                Document(page_content=text, metadata=meta)
                for text, meta in zip(batches[i], metadata_batches[i])
            ]
            vectorstore.add_documents(docs_batch)

            if i % 10 == 0:
                temp_save_path = f"{save_path}_temp"
                os.makedirs(os.path.dirname(temp_save_path) if os.path.dirname(temp_save_path) else '.', exist_ok=True)
                vectorstore.save_local(temp_save_path)
                print(f"Temporary vector store saved to {temp_save_path} after batch {i}")

        except Exception as e:
            print(f"Error processing batch {i}: {e}")
            error_save_path = f"{save_path}_error_at_batch_{i}"
            os.makedirs(os.path.dirname(error_save_path) if os.path.dirname(error_save_path) else '.', exist_ok=True)
            vectorstore.save_local(error_save_path)
            print(f"Partial vector store saved to {error_save_path}")
            raise

    os.makedirs(os.path.dirname(save_path) if os.path.dirname(save_path) else '.', exist_ok=True)
    vectorstore.save_local(save_path)
    print(f"Vector store saved to {save_path}")

    return vectorstore

def load_vector_store(embeddings, load_path="faiss_index_pymupdf_81"):
    if not os.path.exists(load_path):
        raise FileNotFoundError(f"ë²¡í„° ìŠ¤í† ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {load_path}")
    return FAISS.load_local(load_path, embeddings, allow_dangerous_deserialization=True)

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="ë²¡í„° ìŠ¤í† ì–´ êµ¬ì¶•")
    parser.add_argument("--folder", type=str, default="final_dataset", help="ë¬¸ì„œê°€ ìˆëŠ” í´ë” ê²½ë¡œ")
    parser.add_argument("--save_path", type=str, default="vector_db", help="ë²¡í„° ìŠ¤í† ì–´ ì €ì¥ ê²½ë¡œ")
    parser.add_argument("--batch_size", type=int, default=4, help="ë°°ì¹˜ í¬ê¸°")
    parser.add_argument("--model_name", type=str, default="intfloat/multilingual-e5-large-instruct", help="ì„ë² ë”© ëª¨ë¸ ì´ë¦„")
   # parser.add_argument("--device", type=str, default="cuda", help="ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ ('cuda' ë˜ëŠ” 'cpu')")
    parser.add_argument("--device", type=str, default="cuda", help="ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ ('cuda' ë˜ëŠ” 'cpu' ë˜ëŠ” 'cuda:1')")

    args = parser.parse_args()

    # ë¬¸ì„œ ì²˜ë¦¬ ëª¨ë“ˆ import
    from document_processor_image_test import load_documents, split_documents

    documents = load_documents(args.folder)
    chunks = split_documents(documents, chunk_size=800, chunk_overlap=100)

    print(f"[DEBUG] ë¬¸ì„œ ë¡œë”© ë° ì²­í¬ ë¶„í•  ì™„ë£Œ, ì„ë² ë”© ë‹¨ê³„ ì§„ì… ì „")
    print(f"[INFO] ì„ íƒëœ ë””ë°”ì´ìŠ¤: {args.device}")

    try:
        embeddings = get_embeddings(
            model_name=args.model_name,
            device=args.device
        )
        print(f"[DEBUG] ì„ë² ë”© ëª¨ë¸ ìƒì„± ì™„ë£Œ")
    except Exception as e:
        print(f"[ERROR] ì„ë² ë”© ëª¨ë¸ ìƒì„± ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
        import traceback; traceback.print_exc()
        exit(1)

    build_vector_store_batch(chunks, embeddings, args.save_path, args.batch_size)

