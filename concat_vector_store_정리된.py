import os
import glob
from langchain.schema.document import Document
from e5_embeddings import E5Embeddings
from langchain_community.vectorstores import FAISS
from document_processor import load_pdf_with_pymupdf, split_documents

# ê²½ë¡œ ì„¤ì •
FOLDER = "25.05.28 RAGìš© 2ì°¨ ì—…ë¬´í¸ëŒ ì·¨í•©ë³¸"
VECTOR_STORE_PATH = "vector_db"

# 1. ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
def get_embeddings(model_name="intfloat/multilingual-e5-large-instruct", device="cuda"):
    return E5Embeddings(
        model_name=model_name,
        model_kwargs={'device': device},
        encode_kwargs={'normalize_embeddings': True}
    )

# 2. ê¸°ì¡´ ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ
def load_vector_store(embeddings, load_path=VECTOR_STORE_PATH):
    if not os.path.exists(load_path):
        raise FileNotFoundError(f"ë²¡í„° ìŠ¤í† ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {load_path}")
    return FAISS.load_local(load_path, embeddings, allow_dangerous_deserialization=True)

# 3. ì •ë¦¬ëœ PDFë§Œ ì„ë² ë”©
def embed_cleaned_pdfs(folder, vectorstore, embeddings):
    pattern = os.path.join(folder, "ì •ë¦¬ëœ*.pdf")
    pdf_files = glob.glob(pattern)
    print(f"ğŸ§¾ ëŒ€ìƒ PDF ìˆ˜: {len(pdf_files)}")

    new_documents = []
    for pdf_path in pdf_files:
        print(f"ğŸ“„ ì²˜ë¦¬ ì¤‘: {pdf_path}")
        text = load_pdf_with_pymupdf(pdf_path)
        if text.strip():
            new_documents.append(Document(page_content=text, metadata={"source": pdf_path}))

    print(f"ğŸ“š ë¬¸ì„œ ìˆ˜: {len(new_documents)}")

    chunks = split_documents(new_documents, chunk_size=300, chunk_overlap=50)
    print(f"ï¿½ï¿½ ì²­í¬ ìˆ˜: {len(chunks)}")

    print(f"ì¶”ê°€ ì „ ë²¡í„° ìˆ˜: {vectorstore.index.ntotal}")
    vectorstore.add_documents(chunks)
    print(f"ì¶”ê°€ í›„ ë²¡í„° ìˆ˜: {vectorstore.index.ntotal}")

    vectorstore.save_local(VECTOR_STORE_PATH)
    print(f"âœ… ì €ì¥ ì™„ë£Œ: {VECTOR_STORE_PATH}")

# ì‹¤í–‰
if __name__ == "__main__":
    embeddings = get_embeddings()
    vectorstore = load_vector_store(embeddings)
    embed_cleaned_pdfs(FOLDER, vectorstore, embeddings)
